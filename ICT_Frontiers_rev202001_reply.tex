% \input{ICT_Frontiers_rev202001.tex}
\documentclass[utf8]{article}
% \usepackage{RevisionToolsByAcer}
% \ProvidesPackage{RevisionToolsByAcer}
% \documentclass[utf8]{article}
% \ProvidesPackage{RevisionToolsByAcer}
%% Language and font encoding
\usepackage[english]{babel}
\usepackage[round, sort]{natbib}
\usepackage[T1]{fontenc}



% ============================ Sourcing main file ============================ %
\usepackage{xr}
\externaldocument{ICT_Frontiers_rev202001}
\usepackage{lineno}





% Sets page size and margins
% \usepackage[a4paper, top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=4cm]{geometry}
\usepackage[papersize={10in, 12in}, top=3cm,bottom=2cm,left=2in,right=2in,marginparwidth=1.8in]{geometry}
\usepackage{titlesec}
\usepackage[dvipsnames,table,xcdraw]{xcolor}
\usepackage[at]{easylist}
\usepackage[round]{natbib}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{authblk}
\usepackage{float}
\usepackage{tikz}
\usepackage[threshold=2, autopunct=true, autostyle=true]{csquotes}
\usepackage[colorinlistoftodos]{todonotes}


% =============================== Header style =============================== %
\titlelabel{}


% ============================================================================ %
%                               Macros from Acer                               %
% ============================================================================ %

		
% --------------------------------- Question --------------------------------- %	
\newcounter{cQuestion}[section]
\newenvironment{question}
    {\refstepcounter{cQuestion}\color{Blue}\noindent\newline Q\thecQuestion:}
    {~\newline}
    
% ------------------------------------ Ans ----------------------------------- %
\newenvironment{ans}  
    {\color{Black}\noindent A:}
    {~\newline}    
    
    
\newcommand{\QA}[2]{
    \begin{question}  
        #1
    \end{question}
        
    \begin{ans}  
        #2
    \end{ans}
}

% ---------------------------------- Revise ---------------------------------- %
% \Revise{Page}{original text}{revised text}
\newcommand{\revise}[3]{
	\newline
	\newline
    \noindent
    \textbf{line #1:}
    \newline
    Original:\newline
    \textit{"#2"}
    \newline
    \newline
    Revised:\newline
    \textit{"#3"}\newline}

% ---------------------------------- Add New --------------------------------- %
% \addnew{line number}{text}
\newcommand{\addnew}[2]{\blockcquote{}{Line #1:~\newline\textit{"#2"}}
}

% ================================ Annotation ================================ %
\newcommand{\toWrite}[1]{\noindent
	\textcolor{Orange}{\textbf{[[ #1 ]]}}}


% =================================== Title ================================== %
\title{Response to Reviewers $Rev^1$}
\date{\today}
\author{} 



% =================================== Begin ================================== % 
\begin{document}

    \maketitle
    \section*{Reply to Editor}
        \begin{question}
        In addition, I have a question. if we view molecules as coarse grains of elementary particles, would the phenomenon of molecular recognition have high NTIC and thus be conscious?
        \end{question}
        
        \begin{ans}
            Hi Prof. Hoffman,
            Thank you for your attention to our manuscript and your interesting question. \\
            There is no question that molecular complexes are coarse-grainings of molecules via molecular recognition. Based on our hypothesis, if the dynamics of a molecular complex is an NTIC process, the information closure theory of consciousness (ICT) would claim that the molecular complex has a certain degree of consciousness. Therefore, to your question, it is theoretically plausible under the framework of ICT. We speculate that it may be easy to find informationally closed molecular complexes (isolated complexes) but may not be easy to find ones forming NTIC processes. Nevertheless, with well-defined mathematical definition, this is an empirical and testable question to ICT. We look forward to learning any self-assembly process forming NTIC at molecular scales in the near future.        
        \end{ans}
        
    
    \section{Reply to Reviewer 1}
        \begin{question}
            Regarding the NTCI measure: \\\\
            a) Bertschinger et al. 2006 define informationally closed as $J_t(E -> Y) = 0$, but this is not a requirement for NTIC. Meaning, a positive NTIC measure does not entail that $J_t = 0$. $J_t = 0$ is only true if the NTIC is equal to $I(Y_{t+1}; E_t)$. In what sense does it correspond to non-trivial information closure then? (see also my concern \#2, maybe that is related) As defined in eq. 6 a video camera might have very high NTIC if it records a natural scene, even though it is in no way informationally closed from the environment.\\\\
            b) Is $NTIC_t$ state dependent or not? As capital letters are used I assume it is based on (conditional) mutual information measures across one time step but averaged over the possible states of the system at time t and t+1, so state distributions. But which distributions are used to compute $NTIC_t$? The stationary joint distribution of states at t and t+1? It cannot be just some observed measure, because then the level of consciousness would depend on how long the observation is. Moreover, if $NTIC_t$ is not state dependent, then the Reflex example on p. 10 is not intuitive. Because the system (brain) is the same and awake whether it behaves reflexively or not, so while the content may depend on the type of action, the $NTIC_t$ (level) would stay the same.              
        \end{question}
    
    	\begin{ans}
    		\newline
    		a) Considering Eq.\ref{eq:NTIC2}, it is true that the transfer entropy term $J_t(E -> Y)=0$ is not required for $NTIC>0$. It is possible to have a high degree of NTIC when $J_t(E -> Y) > 0$, i.e. the process is not completely closed.  \\
    		However, based on the setting in both Bertschinger et al. 2006 and our Section 2 (at Line \lineref{line:r1q1a}), $Y_{t+1}$ is determined by both $Y_t$ and $E_t$. Simply increasing $I(Y_{t+1}; E_t)$ without closedness (e.g, copy the information in sensory signals to the process such as the case in the video camera example), the transfer entropy term $J_t(E -> Y)$ should increase at the same rate and cancel out the increment of $I(Y_{t+1}; E_t)$ resulting low NTIC. Namely, keeping high closedness, i.e. minimising $J_t(E -> Y)$, is crucial to increase NTIC even though $J_t(E -> Y) > 0$.\\
    		In our current version of ICT, we consider the level of consciousness corresponds to the degree of NTIC of a process. Therefore, a conscious process does not have to be completely closed. However, a high degree of closedness is crucial to have a high level of consciousness.\\
    		
    		\noindent
    		b) Thank the reviewer for this outstanding question. We entirely agree that state-dependent measurements are essential to describe the dynamics of conscious experience. In fact, we now are working on state-dependent formulations for the next version of the ICT. In contrast to the current version, this work involves point-wise informational measures and certainly require more space and discussion. Therefore, we prefer to address the state-dependent version of ICT in future studies and keep the first version of our theory simple.\\
    		We appreciated that the reviewer pointed this out. We have added a short paragraph about this issue.
    	
	    	\addnew{\lineref{line:r1-state-dep}}{
	    		In this article, we do not use a state-dependent formulation of NTIC in the current version of ICT. However, we believe that the state-dependent NTIC is essential to describe the dynamics of conscious experience. Therefore, further research using point-wise informational measures to construct state-dependent NTIC is needed in the next version of ICT.}
	    	
	    		
	    		
    	\end{ans}
        
       
        
        \begin{question}
            Hypothesis and Implication 3: Why is it crucial that there is an underlying X with respect to which Y is a C-process? Does Y being informationally closed with respect to X imply that Y is also informationally closed with respect to E, i.e. $J_t(E-Y) = 0$? I don't think that could be true for the brain, or part of it really. My brain's next state, at whatever level, certainly depends to some degree on unpredictable sensory inputs from the environment. In the end, is $I(Y_{t+1}; E_t|Y_t) = 0$ required for consciousness or not? (see point 1a). In other points in the manuscript this does not seem required, e.g. p. 10 "If a process is not informationally closed, the degree of NTIC is low resulting in low or no consciousness".        
        \end{question}
        
        \begin{ans}        	
            Because X is the micro-level of the universe, any coarse-graining of X (including E and S) should have equal or less information about Y than X, i.e. $I(Y_{t+1}; X_t|Y_t) \geq I(Y_{t+1}; S_t|Y_t)$ and  $I(Y_{t+1}; X_t|Y_t) \geq I(Y_{t+1}; E_t|Y_t)$. Therefoe, Y is informationally closed with respect to X implying that Y is also informationally closed with respect to S, E, and all other coarse-grainings of X. As explained in Question 1a, it is not required for NTIC processes to be completely closed. Therefore, the closedness of Y with respect to X $I(Y_{t+1}; X_t|Y_t)$ serves as the lower bound of the closedness of Y to any other processes. 
            For this first exposure of our theory, we did not discuss NTIC in the context of the temporal coarse-graining. It is true that we certainly encounter some degree on unpredictable sensory inputs from the environment from time to time. Therefore, NTIC should be higher for finer temporal scales than for coarser temporal scales. We also speculate that the temporal coarse-graining is related to the speed of "stream of consciousness" and will address this issue in our future studies. 
        \end{ans}
        
        
        \begin{question}
            Exclusion or no exclusion? The authors state multiple times that "every process with a positive non-trivial information closure (NTCI) has consciousness." (p.3, and also p.12).
            a) Yet, Figure 4 is ambiguous in the sense that the maximum somehow seems important, while actually all levels should give rise to separate experiences. I don't see how ICT without something like exclusion (IIT style) would indicate that the maximum should correspond to human consciousness. It could just be any one out of many consciousnesses.
            b) p. 14: comparison to IIT: what does ICT say about different sets of variables at the same level. There might well be multiple ways to partition X into S and E, with many overlapping S's. Would those all be conscious? They would not be informationally closed from each other but they could all fulfill the requirements in the Hypothesis. It seems like finding the maximum within a level over the possible sets of elements/variables is a necessary step to identify boundaries (I think also Krakauer does that across sets of variables, but not 100\% sure)        
        \end{question}
    
    	\begin{ans}
    		
    		
    	\end{ans}

        
        \begin{question}
            Feedback and memory: p. 11. If $NTIC > 0$ is sufficient and true information closure is not required, then feedfoward networks can be conscious according to ICT. Also, in that case, memory is not necessary, as the video camera would have $NTIC > 0$ as long as it records from a stable environment. In that case $I(Y_{t+1}, Y_t) > 0$ and $I(Y_{t+1}, Y_t|E_t)$ is small. This issue here is that having information about the next state does not imply that there is any causation, so if $Y_t$ is highly correlated with $E_t$ and $E_t$ causes $Y_{t+1}$ then NTIC is high. (Thus the IIT emphasis on causation).\\
            If somehow the fact that Y must be informationally closed wrt X does the heavy-lifting here that should be made more explicit (see above).
        \end{question}
        
        \begin{question}
            Does ICT imply that one is unconscious while dreaming? In that case $I(Y_{t+1}; Y_t|E)$ should almost be identical to $I(Y_{t+1};I_t)$ and thus lead to NTIC approx. 0.        
        \end{question}
    
    	\begin{ans}
    		\toWrite{Add something here}
    		We have added a paragraph at Line \lineref{line:dream}
    	\end{ans}
        
        
        \begin{question}
            Minor:
            \begin{enumerate}
                \item "contributions to the field" This section is just a copy paste from the abstract and thus not necessarily helpful. Not sure though what the purpose of this section is meant to be by Frontiers.
                
                \item Introduction: "We currently lack a theory... " IIT and the geometric theory of consciousness (Fekete et al.) have proposed solutions. So there are theories. The following paper should be of interest and should probably be cited:
                Fekete T, van Leeuwen C, Edelman S (2016) System, subsystem, hive: Boundary problems in computational theories of consciousness. Front Psychol 7:1041.
                
                \item $y_t$ corresponds to the content. I would argue that an activation state, without taking the system or relation between elements etc into account is meaningless and cannot capture/explain the structure of an experience. Though this issue can be dealt with at a later time.
            \end{enumerate}
        \end{question}
    
    	\begin{ans}
    		\begin{enumerate}
    			\item It's true that we were also confused about it during submission. 
    			We have modified this as follows: \\
    			\toWrite{"contributions to the field"}
    			
    			\item Thank the reviewer for this suggestion. We have modified our manuscript and cited  the reference at Line \lineref{line:lack-theory}. \toWrite{Change main text}
    			
    			\item We fully agree with the reviewer's comment. 
    			In fact, in our theory, we do not partition states of processes into activation and relation. For example, both activation and structure states of a neural network should be considered. After all, they can be parameterised as the parameters of processes. The only difference is the temporal scales of parameter changes. States of activation may have more rapid dynamics than states of relation. In ICT, this difference is crucially related to the temporal coarse-graining which we did not address in this article but can be easily generalised in future versions of ICT. 
    			
    			\toWrite{To write something in the main text?}
    			
    			
    		\end{enumerate}
    		
    	\end{ans}
        
        
    \section{Reply to Reviewer 2}
        \begin{question}
			I had a few problems in reading the paper, which I think should be addressed (especially the first) before the paper is published. For detailed notes on these see below.
			
			\begin{enumerate}
				\item The coarse-graining idea seems undefined in critical ways, but the paper reads as though it is well-defined. So maybe the authors have compressed too much detail? In the formalism presented it is unclear what coarse-graining (or information closure to other grains) amounts to. With this lack of detail, it is then unclear to me why intermediate maxima in IC are a plausible result (why does IC not just decline with progressive coarse graining).
				
				\item The idea of 'simulation'. This is a more minor point but I would appreciate if the authors could be clearer on this. It is arguable whether or not consciousness simulates anything (e.g. see Hoffman's interface theory); and some of the assertions the authors make re simulation seem unfounded anyways. But it could be that they mean something different or subtle (that consciousness is linked to or represents or etc the environment)\todo{I don't understand this question well}
				
				\item There were several other assertions that stood out to me as strange or wrong, but could be a matter of explanation or ignorance on my part (the feedforward system, the cut-apart system). Either way some more explanation would be good.
			\end{enumerate}
        \end{question}
    
    
    	\begin{ans}
    		\begin{enumerate}
    			\item In this article, the definition of coarse-graining is our "Definition 1" (line: \lineref{line:r2q1-1}) which is simply a function mapping a stochastic process $X$ with state space $\mathcal{X}$ to a stochastic process $Y$ with state space $\mathcal{Y}$.
    			We do not specify any specific types of coarse-graining.
    			\toWrite{Instead, our hypothesis states that any process which coarse-graining which}
    			
    			We emphasise the non-monotonic relation between the scales of coarse-graining and the degrees of NTIC. However, we do not exclude the possibility that there exist multiple NTIC picks across scales of coarse-graining of a process. 
    			This implies that we do not exclude the possibility that there exist multiple high conscious processes at different scales. 
    			(However, due to IC, conscious processes are not able to know the existence of each other. 
					\todo{Discuss this}
					
					
    			\item \toWrite{TBD}
%    			\item \toWrite{After replying the first reviewer}
    		\end{enumerate}
    		
    	\end{ans}
    
    
    	
        
        
        \begin{question}
			The English is not perfect and needs some good proofreading, though it was understandable throughout.
        \end{question}
    
    
    	\begin{ans}
    		\todo{What should we deal with this?}
    	\end{ans}
    
    
    	\begin{question}
			On line 182, defining C-processes as cases where ‘Y is informationally closed to X’. This is now information closure in the sense of coarse-graining, but no such thing has been defined yet? Is it supposed to be so trivial that it is not required to make it explicit? To this point, closure is defined entirely in terms of system with respect to environment.
			
			Basically, I am not sure whether closer between scales is a matter of same-time (e.g. $I(Y_{t+1};X_{t+1})$) or across-time interactions ($I(Y_{t+1};X_t)$). Or could it be both?    		
    	\end{question}
    
    	\begin{ans}
			Here, we followed a common setup of coarse-graining (e.g. \toWrite{cite here}), which does not take time $Y_t=f_Y(X_t)$ (in Definition 1). In this setup, coarse-graining is unidirectional ad does not involve interaction between scales. This means that coarser scales supervene on finer scales, and there exists no top-down causation. \\
			In our hypothesis, Y is IC with respect to the microstate of the universe, X. This is critical in the hypothesis because Y is IC with respect to X, implying that Y is also IC with respect to its intermediate level S and its environment E in Fig. \ref{fig:fullgraph}.\todo{need any change in the main text?}
    	\end{ans}
    
    
    	\begin{question}            
    		On line 241: “.. not sufficiently coarse-grained variables have low values of NTIC”, this is phrased as though it is necessarily true (and also that “we saw above”, though I do not see above where this is justified), but is it?
    		
    		At the very finest grain, wouldn’t even all the most ‘stochastic’ dynamics of a system be accounted for by prior states of the system, or by the environment? Why wouldn’t we assume that NTIC *only decreases* as the system is coarse-grained (as number of elements/states is decreased), for similar reasons as it must be zero at a 1-element 1-state system as the authors note? This seems an important point to be very clear on…
    	\end{question}
    
    	\begin{ans}
    		\toWrite{The reviewer is right?}
    		Thank the reviewer for this critical comment. It is true that NTIC a monotonic function of scales of coarse-graining. NTIC can increase or decrease when the grains are coarser. We are currently still working on the relationship between scales and NTIC. 
    		We will systematically address NTIC and functions of coarse-graining in our following studies. 
    		Further more, in our current analysis, it seems that this is also related to informational synergy and redundancy. We aim for presenting the core concept of ICT in this article.
    		The reviewer's critical question is on our list of future work. 
    		\toWrite{Need to change the text a lot!!}
    	\end{ans}
    
    
    	\begin{question}
    		on line 263: “NTIC processes encodes environmental information in its state. This suggests that a NTIC process can be considered as a process that simulates the environmental dynamics.“
    		
    		Why does encoding suggest simulation? An encoding *could* be a simulation, but it could well be nothing like a simulation, if we understand simulation to mean something like an imitation or reconstruction of some structure or dynamics. Two totally different environmental situations could potentially be encoded in exactly the same way (eg. as a string of 1s and 0s).
    		
    		The ‘simulation’ notion is brought up again in section 5.2 (line 344), citing Bertschinger et al, though I do not find the idea in that paper.. I think authors need to be clearer on what they mean by ‘simulation’ to make this point.
    	\end{question}
    
    	\begin{ans}
    		Thank the reviewer for this mindful comment. 
    		Our description indeed is not clear enough. The environmental information here about not only states but also state transitions. 
    		This is because high NTIC implies high mutual information between a process and its environment $I(Y_{t+1};E_t)$ (Eq. \ref{eq:nticObjective2}). Therefore, the dynamics of the process $Y$ needs to covary with the dynamics of its environment $E$. Here, we consider 'simulation' is a more precise expression than 'encoding'. 
    		The notion of simulation is the same as the 'Modeling' case on Page 4 in Bertschinger et al. , 2006: \\
    		\textit{"B2)~Modeling: The system reaches synchronization and internalizes the correlations observed in the environment by building up own structures."}
    		\\ \toWrite{add something in the main text}
    	\end{ans}
    
   	\begin{question}
			line 306: “Blindsight patients… make above chancel-level visual judgments without having any conscious perception about visual stimuli” I am not sure this characterization of blindsight is correct, it may be a matter of the phrasing. It could be - or probably is - the case that ‘blindsight’ patients always have some conscious experience of what drives their correct responses, but that the “visual character” of these experiences is degraded or missing.
			(Overgaard, Experimental Brain Research 2011)
			for a specific example
			(Mazzi, Bagattini, Savazzi; Frontiers in Psychology, 2016)
    	\end{question}
    
    
   		\begin{ans}
   			Thank the reviewer for the clarification. 
   			Yes, we specifically address the visual character of their experience.
   			We have changed our sentence as follows:
   			\revise{\lineref{line:r2q6}}
   			{
   				Blindsight patients are able to track objects, avoid obstacles, and make above chance-level visual judgements without having any conscious perception about visual stimuli.
   			}
   			{
   				Blindsight patients are able to track objects, avoid obstacles, and make above chance-level visual judgements when their visual experiences is degraded or missing (however, they may still preserve some forms of conscious experience, see \cite{overgaard2011visual, mazzi2016blind}). 
   			}
   		\end{ans}
    
    
    
    
    	\begin{question}
            on Line 316: On the issue of a feedforward network, the current state of a feedforward network with more than one layer is certainly driven by its own past states! So, mutual information of a feedforward network over a time lag should not be zero, unless I am misunderstanding something here?
			At the same time, I can see a version of the authors' argument here - for a unit in a feedforward network with depth (distance-from-input) of N, a time lag of N time steps would always account fully for the states of the element. Is this the idea?		
    	\end{question}
    
 		\begin{ans}
 			Thank the reviewer for this valuable comment. 
 			\begin{figure}[H]
 				\centering
 				\includegraphics[width=\textwidth]{WritingMaterials/Fig_ScaleProblemOfConsciousness/ScaleProblemOfConsciousness.pdf}
 				\caption{The scale problem of consciousness: Human conscious experience does not reflect information from every scale. Only information at a certain coarse-grained scale in the neural system is reflected in consciousness.}
 				\label{fig:scaleproblem}
 			\end{figure}
 			
 			Indeed, 
 			\\
 			\toWrite{This is really a good question.}
 			\todo{Indeed, if information is just copied to the process, it will still be NTIC. Feedforward is just a way to copy the information}
 		\end{ans}
 	
    
    	\begin{question}
    		on line 441: under the 'Prediction after system damaged', it is suggested that ICT predicts cutting a system in half would render both halves unconscious. But this would only be the case if neither half contains its own C-processes, yes? Since ICT allows that many C-processes can exist at the same time, it would have to be some special case for this prediction to hold true. So it seems to me the prediction is actually similar to that of IIT.
    	\end{question}
    
    
    	\begin{ans}
    		Thank the reviewer for this considerate comment. The reviewer is correct. This prediction is under an assumption which we did not explicitly specify in our last version. We assume that we have one conscious (NTIC) process involving information in both brain hemispheres. Namely, the process is informationally closed only when we consider the information in both hemispheres. We agree that if both hemispheres have their own NTIC proceess ICT should predict no change of conscious experience before and after cutting. Cutting should not make any difference because they are informationally closed with respect to each other. We also agree that this prediction is relatively premature. However, we also acknowledge the strength of all computational theories of consciousness. The reviewer's question is empirical to us under formal mathematical formulations of ICT and IIT. Systematical comparisons between model predictions can be done by rigorous modelling studies in the future. 
    		
    		\toWrite{The original paragraph has been changed as follows: lline \lineref{line:r2-cutting}:}
    	\end{ans}
    
                
        \begin{question}                                                                   
            Line 540: the theory doesn’t really seem to intend to solve the hard problem(s) at all, much less “completely solve”.            
            I was expecting the problem of dreaming to come up in the last section (maybe along with SMC for which it is a serious problem). When dreaming the information between environment and the system is virtually zero; is this a problem for ICT? Also, more specific phenomena like the eigengrau - if you take away all visual input, for long enough, I do not lose my visual experiences - rather they take on a special state. Does ITC need to accept the possibility that even *trivial* IC can be a conscious process?
        \end{question}
    
    	\begin{ans}
    		ICT is our first attempt to approach the hard problem of consciousness. We hope that ICT and our following works can establish an informational perspective on conscious experience. Instead of solving the hard problem of consciousness, we more look forward to mathematically determining whether the hard problem can be solved or not by information theory. However, because the relevant discussion is clearly outside the scope of this article, we prefer not to discuss the hard problem here. n
    		
    		It is important to note that we reckon only part of the neural system is involved in the NTIC process(es). This is due to the fact that some parts of the neural system are evidently not informationally closed. They only passively react to sensory inputs or other parts of the neural system. 
    		To the NTIC process(es), the rest of the neural system is considered as the environment. This notion is shortly indicated at line \lineref{line:neu-env}.
    		We speculate that, during dreaming, the neural system can still form the NTIC process(es) with respect to other parts of the neural system which we know they maintain high activities. The same idea can be also applied to phenomena like Eigengrau. However, at the current stage, this is mere speculation so we restrained ourself from making the statement in our last version of the manuscript. However, thank the reviewer for bringing up this question. We believe that it is still worth to mention issues about dreaming. We have added a short paragraph as follows:
    		
    		\toWrite{add something in the main text at Line \lineref{line:dream}}
    		    
    		Finally, we believe that this is also a clear empirical question that can be tested in future studies. 
    	\end{ans}

	\bibliography{ref}
\end{document}
