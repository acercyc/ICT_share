% \input{ICT_Frontiers_rev202001.tex}
\documentclass[utf8]{article}
% \usepackage{RevisionToolsByAcer}
% \ProvidesPackage{RevisionToolsByAcer}
% \documentclass[utf8]{article}
% \ProvidesPackage{RevisionToolsByAcer}
%% Language and font encoding
\usepackage[english]{babel}
\usepackage[round, sort]{natbib}
\usepackage[T1]{fontenc}



% ============================ Sourcing main file ============================ %
\usepackage{xr}
\externaldocument{ICT_Frontiers_rev202001}
\usepackage{lineno}





% Sets page size and margins
% \usepackage[a4paper, top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=4cm]{geometry}
\usepackage[papersize={10in, 12in}, top=3cm,bottom=2cm,left=2in,right=2in,marginparwidth=1.8in]{geometry}
\usepackage{titlesec}
\usepackage[dvipsnames,table,xcdraw]{xcolor}
\usepackage[at]{easylist}
\usepackage[round]{natbib}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{authblk}
\usepackage{float}
\usepackage{tikz}
\usepackage[threshold=2, autopunct=true, autostyle=true]{csquotes}
\usepackage[colorinlistoftodos]{todonotes}


% =============================== Header style =============================== %
\titlelabel{}


% ============================================================================ %
%                               Macros from Acer                               %
% ============================================================================ %

		
% --------------------------------- Question --------------------------------- %	
\newcounter{cQuestion}[section]
\newenvironment{question}
    {\refstepcounter{cQuestion}\color{Blue}\noindent\newline Q\thecQuestion:}
    {~\newline}
    
% ------------------------------------ Ans ----------------------------------- %
\newenvironment{ans}  
    {\color{Black}\noindent A:}
    {~\newline}    
    
    
\newcommand{\QA}[2]{
    \begin{question}  
        #1
    \end{question}
        
    \begin{ans}  
        #2
    \end{ans}
}

% ---------------------------------- Revise ---------------------------------- %
% \Revise{Page}{original text}{revised text}
\newcommand{\revise}[3]{
	\newline
	\newline
    \noindent
    \textbf{Line #1:}
    \newline
    Original:\newline
    \textit{"#2"}
    \newline
    \newline
    Revised:\newline
    \textit{"#3"}\newline}

% ---------------------------------- Add New --------------------------------- %
% \addnew{line number}{text}
\newcommand{\addnew}[2]{\blockcquote{}{\textbf{Line #1:}~\newline\textit{"#2"}}
}

% ================================ Annotation ================================ %
\newcommand{\toWrite}[1]{\noindent
	\textcolor{Orange}{\textbf{[[ #1 ]]}}}


% =================================== Title ================================== %
\title{Response to Reviewers $Rev^1$}
\date{\today}
\author{} 



% =================================== Begin ================================== % 
\begin{document}

    \maketitle
    \section*{Reply to Editor}
        \begin{question}
        In addition, I have a question. if we view molecules as coarse grains of elementary particles, would the phenomenon of molecular recognition have high NTIC and thus be conscious?
        \end{question}
        
        \begin{ans}
            Hi Prof. Hoffman,
            Thank you for your attention to our manuscript and your interesting question. \\
            If we understand correctly, molecular recognition refers to specific types of interactions among molecules that form molecular complexes. There is no question that molecular complexes are coarse-grainings of molecules via molecular recognition. Based on our hypothesis, if the dynamics of a molecular complex is an NTIC process, the information closure theory of consciousness (ICT) would claim that the molecular complex has a certain degree of consciousness.
        \end{ans}
        
    
    \section{Reply to Reviewer 1}
        \begin{question}
            Regarding the NTCI measure: \\\\
            a) Bertschinger et al. 2006 define informationally closed as $J_t(E\rightarrow Y) = 0$, but this is not a requirement for NTIC. Meaning, a positive NTIC measure does not entail that $J_t = 0$. $J_t = 0$ is only true if the NTIC is equal to $I(Y_{t+1}; E_t)$. In what sense does it correspond to non-trivial information closure then? (see also my concern \#2, maybe that is related) As defined in eq. 6 a video camera might have very high NTIC if it records a natural scene, even though it is in no way informationally closed from the environment.\\\\
            b) Is $NTIC_t$ state dependent or not? As capital letters are used I assume it is based on (conditional) mutual information measures across one time step but averaged over the possible states of the system at time t and t+1, so state distributions. But which distributions are used to compute $NTIC_t$? The stationary joint distribution of states at t and t+1? It cannot be just some observed measure, because then the level of consciousness would depend on how long the observation is. Moreover, if $NTIC_t$ is not state dependent, then the Reflex example on p. 10 is not intuitive. Because the system (brain) is the same and awake whether it behaves reflexively or not, so while the content may depend on the type of action, the $NTIC_t$ (level) would stay the same.              
        \end{question}
    
    	\begin{ans}
    		\newline
    		a) It is true it is true that the information flow term $J_t(E\rightarrow Y)$ does not have to be zero for $NTIC>0$. However, in Definition 2, a C-process is informationally closed to the microscopic universe process $X$. This implies C-process is also informationally closed to any other coarse-grainings of X including E (see also our reply to Q2). Currently, we only consider closed NTIC processes are C-processes. 
    		Regarding the video camera example, please see more discussion in our reply to your Q6. \\
    		
    		% Backup 2020/04/07 14:23
    		% ====================================
            % 		a) Considering Eq.\ref{eq:NTIC2}, it is true that the transfer entropy term $J_t(E\rightarrow Y)$ does not have to be zero for $NTIC>0$. It is possible to have a high degree of NTIC when $J_t(E\rightarrow Y) > 0$, i.e. the process is not completely closed. We consider NTIC here as just the quantity defined in Eq.\ref{eq:NTIC2}.   \\

            %         Therefore, a conscious process does not have to be completely closed. 
            %         However, processes that manage to reduce the transfer entropy from the environment without reducing their mutual information with the environment achieve higher levels of consciousness. 
            %         Regarding the video camera example, please see more discussion in our reply to your Q6. \\
            % ====================================
            		
    		\noindent
    		b) It is true that NTIC is not state-dependent. We agree that state-dependent measurements are essential to describe the dynamics of conscious experience. We are  working on state-dependent formulations for the next version of the ICT. In contrast to the current version, this work involves point-wise informational measures and requires more space and discussion. Therefore, we prefer to address the state-dependent version of ICT in future studies and keep the first version of our theory simple.\\
    		We appreciated that the reviewer pointed this out. We have added a short paragraph about this issue.
    	
	    	\addnew{\lineref{line:r1-state-dep}}{
	    		In this article, we do not use a state-dependent formulation of NTIC. However, we believe that the state-dependent NTIC is essential to describe the dynamics of conscious experience. Therefore, further research using point-wise informational measures to construct state-dependent NTIC is needed for the next version of ICT.}
    	\end{ans}
        
       
        
        \begin{question}
            Hypothesis and Implication 3: Why is it crucial that there is an underlying $X$ with respect to which $Y$ is a C-process?     
        \end{question}
        
        \begin{ans}        	
            The C-processes are constructed to answer questions about the scale problem of consciousness. Their definition therefore states their relation to the microscopic scale $X$. 
            At the same time it would be possible to remove $X$ from the definition and instead require that $Y$ is informationally closed with respect to all other processes. In some cases such a definition would be more general than the present one for example when there is no final microscale and instead there is an infinite number of more and more microscopic scales. However, we find the use of an explicit microscale $X$ easier to understand and sufficient to communicate the idea. Note that closure with respect to $X$ (if it exists) implies closure with respect to every coarse-graining of $X$.   
            To see this note that the information transfer from any coarse-graining (including $E$ and $S$) of $X$ to $Y$ must be lower than that from $X$ to $Y$, i.e. $I(Y_{t+1}; X_t|Y_t) \geq I(Y_{t+1}; S_t|Y_t)$ and $I(Y_{t+1}; X_t|Y_t) \geq I(Y_{t+1}; E_t|Y_t)$. So that $Y$ is informationally closed with respect to $X$ implies that $Y$ is also informationally closed with respect to $S, E$, and all other coarse-grainings of $X$.
        \end{ans}
        
        \begin{question}
            Does $Y$ being informationally closed with respect to $X$ imply that $Y$ is also informationally closed with respect to E, i.e. $J_t(E\rightarrow Y)= 0$? I don't think that could be true for the brain, or part of it really. My brain's next state, at whatever level, certainly depends to some degree on unpredictable sensory inputs from the environment. In the end, is $I(Y_{t+1}; E_t|Y_t) = 0$ required for consciousness or not? (see point 1a). In other points in the manuscript this does not seem required, e.g. p. 10 "If a process is not informationally closed, the degree of NTIC is low resulting in low or no consciousness".    
        \end{question}
        
        \begin{ans}
            Yes. As mentioned in our answer to Q2 $Y$ being informationally closed with respect to $X$ implies that $Y$ is also informationally closed with respect to E, i.e. $J_t(E\rightarrow Y) = 0$.
            As explained in Question 1a, we currently only consider informationally closed processes as C-processes. The reviewer is also correct that our internal states depends to some degree on unpredictable sensory inputs from the environment. This results in some interesting predictions. For example, the unpredicted sensory inputs may temporally break informational closure and ICT predicts that conscious agents may then lose consciousness for a short time. Unfortunately, referring to your Q1b, the current version of ICT does not include state-dependent IC and NTIC. Therefore, the current formulation of ICT cannot well describe the dynamics of conscious experience under unpredictable states. We expect that our next version of ICT can better answer your question. 
            
            % it is not required for NTIC processes to be completely closed. The information transfer from $X$ to $Y$ $I(Y_{t+1}; X_t|Y_t)$ (if non-zero) serves as the upper bound of the information transfer from any other process to Y. So unpredictable sensory inputs will contribute to a positive information transfer. 
            % As mentioned before higher NTIC values are achieved when this information transfer can be reduced without reducing the mutual information between the sensory inputs and the next system state.
        \end{ans}
        

        \begin{question}
            Exclusion or no exclusion? The authors state multiple times that "every process with a positive non-trivial information closure (NTCI) has consciousness." (p.3, and also p.12).
            a) Yet, Figure 4 is ambiguous in the sense that the maximum somehow seems important, while actually all levels should give rise to separate experiences. I don't see how ICT without something like exclusion (IIT style) would indicate that the maximum should correspond to human consciousness. It could just be any one out of many consciousnesses.
            b) p. 14: comparison to IIT: what does ICT say about different sets of variables at the same level. There might well be multiple ways to partition $X$ into S and E, with many overlapping S's. Would those all be conscious? They would not be informationally closed from each other but they could all fulfill the requirements in the Hypothesis. It seems like finding the maximum within a level over the possible sets of elements/variables is a necessary step to identify boundaries (I think also Krakauer does that across sets of variables, but not 100\% sure)        
        \end{question}
    
    	\begin{ans}
            We can see how Figure 4 was ambiguous with respect to this question. We do not impose the exclusion criterion in ICT and have changed Figure 4 to remove the impression that it does. 
            
            Instead of imposing the exclusion criterion, the concept of informational closure itself already involves the notion of individuality and defining the boundary of a system. \citep{BERTSCHINGER.2006}. This allows ICT to solve the individuality problem of consciousness in some cases (but not all, please see the paragraph in Limitation from Line~\lineref{line:individuality}) without imposing an exclusion criterion. Therefore, it is true that Krakauer's boundary detection procedure can potentially helpful and be adapted for ICT in the future. 
            
            This is also why ICT allows the existence of multiple consciousnesses across the scales of coarse-graining (which IIT does not). Because conscious processes are informationally closed from each other across the scale of coarse-graining, they are not able to know the existence of other consciousnesses within the same system (information flow from other processes is zero). This is in line with using informational closure in level identification \citep{PFANTE.2014}.
            
            We understand that not solving individuality completely is one major weakness of the current version of ICT (and all IC and NTIC based theories). More work on this issue is needed in our following research.
            
            
    	\end{ans}

        \begin{question}
            Feedback and memory: p. 11. If $NTIC > 0$ is sufficient and true information closure is not required, then feedfoward networks can be conscious according to ICT. Also, in that case, memory is not necessary, as the video camera would have $NTIC > 0$ as long as it records from a stable environment. In that case $I(Y_{t+1}, Y_t) > 0$ and $I(Y_{t+1}, Y_t|E_t)$ is small. This issue here is that having information about the next state does not imply that there is any causation, so if $Y_t$ is highly correlated with $E_t$ and $E_t$ causes $Y_{t+1}$ then NTIC is high. (Thus the IIT emphasis on causation).\\
            If somehow the fact that $Y$ must be informationally closed wrt $X$ does the heavy-lifting here that should be made more explicit (see above).
        \end{question}
        
        \begin{ans}
        	The reviewer is right. We have reconsidered case of the feed-forward networks and the video camera example (which can be considered as a single layer feed-forward network). According to ICT, feed-forward networks can be conscious under for deterministic sensor processes. We thank the reviewer to correct this point. In this case also a video camera can achieve positive levels of NTIC and, therefore, be conscious. We have worked extensively on Section \ref{sec:causality} and Section 5 to make this clear (for Section 5, please see from Line:~\lineref{line:notIC}).
        % 	There we have weakened multiple claims in the original version of the manuscript.
        % 	Concerning the camera example we also show that for a camera system filming an environment for which the mutual information from one step to the next is higher than the mutual information between one camera image (sensor values) and the next there are systems that achieve higher NTIC. 
        % 	For the case of the feedforward network we speculate that a similar situation remains true and that there are always systems that achieve higher levels of consciousness than those consisting only of feedforward networks.
        	In summary, we mainly revised our manuscript as follows:
        	\begin{itemize}
        	    \item Add Section \ref{sec:causality} to illustrate two NTIC scenarios about causality. 
        	    \item Add sensory channels in Fig.~2
        	    \item Extensively modify the paragraphs about feed-forward networks and memory in Section 5
        	    \item Add a session in the Appendix to prove that NTIC achieved by modelling the environment can potentially achieve higher NTIC then the one by copying sensory values (e.g., the video camera).
        	\end{itemize}
        	
        	
        	
    %     	Please note that 
        	
		  %  @ The reviewer is correct about the example of the video camera under the condition that the environment past state $E_{t-1}$ shares information with its current state $E_t$, i.e., $I(E_{t-1}, E_t)>0$. 
		    
		  %  @ In such case, simply copying the environmental states to another process (assuming that the sensor of the video camera can capture the whole state of the environment) can lead to positive NTIC. 
		    
		  %  @ This is, in fact, the "Passive adaptation" case mentioned in \cite[p.~4]{BERTSCHINGER.2006},	
		  %  \begin{quote}
			 %     	\textit{"B1)~Passive adaptation: The system is driven by the environment and adapts passively to all changes in the environment. In the case of an environment, that appears deterministic to the system, $H(\hat{e}_{n+1} |\hat{e}_n)=0$, this can be achieved by simply copying the observation of the environment into the system, $S_{n+1} = \hat{e}_n$."}        
		  %  \end{quote} 

	    
	   % @ We can also consider this is a special case of modelling the environment when a system has enough sensory and memory capacities, and, therefore, can virtually model the environment by simply copying the environmental states into the system.  

	   % @ Because this question point to the core concept of ICT, we would like to clarify and emphasise two critical points here. 
	    
	   % @ a) Informational closure and causation: The definition of information closure \citep{BERTSCHINGER.2006} does not involve causation. As described in \cite{BERTSCHINGER.2006}, NTIC can be achieved via "modelling" or "passive adaptation".  In the "modelling" case, the future state of a process ($Y_{t+1}$) can be caused by $Y_t$, which contain predictive information about how the environment influences the system. In the "passive adaptation" case,  the future state of a process ($Y_{t+1}$) is caused by copying environmental information which involves environmental dynamics. 
	    
	   % The latter case may be conceptually counterintuitive because the internal state of the system (e,g, the video camera) is entirely driven by external input. However, it is crucial to know that both cases lead the information flow $J(E\rightarrow Y)$ to (virtually) zero. This means that if $Y_t$ contains information about how the environment $E_t$ causes $Y_{t+1}$, 
	    
	   % However, this is the most critical consequence of solving the scale problem of consciousness in ICT. In physical reality, there only exists microscopic processes at the finest microscopic level. Any causal dependency at coarse-graining levels should be virtual. For example, when $Y$ is informationally closed to X, even though $Y_t$
	    
	   % @ b) As described in our manuscript, to form a higher level of NTIC, the informational richness of the environment, i.e. $H(E)$ also has to be higher since $H(E_t)$ and $H(Y_{t+1})$ both are the upper bound of $I(Y_{t+1}; H(E_t))$. Practically, we believe that with limited sensory and memory capacities, it is difficult to give rise to high NTIC via copying sensory signals to a system. 
	    
        \end{ans}
        
        \begin{question}
            Does ICT imply that one is unconscious while dreaming? In that case $I(Y_{t+1}; Y_t|E)$ should almost be identical to $I(Y_{t+1};I_t)$ and thus lead to NTIC approx. 0.        
        \end{question}
    
    	\begin{ans}
	    	We want to emphasise that not all the processes in the neural system are NTIC processes, since some processes in the neural system are not informationally closed.
	    	To the conscious (NTIC) process, the rest of the neural system is considered as part of the environment. This notion is shortly indicated at line \lineref{line:neu-env} in our first version of the manuscript. These processes are still active during sleep and dreaming. We speculate that, during dreaming, the neural system can stably form the NTIC process with respect to its environment, i.e. other parts of the neural system.  However, at the current stage, this is mere speculation so we restrained ourself from making the statement in our manuscript. However, we thank the reviewer for bringing up this important question. This is also an empirical question that can and should be tested in future studies. We believe that this is still worth mentioning. We have added a short paragraph as follows:
	    	
			\addnew{\lineref{line:dream}}{Explaining conscious experience during dreaming is always a challenge to theories of consciousness. ICT currently does not have a certain answer to dreaming. However, we want to emphasise that not all the processes in the neural system are NTIC since some processes are not informationally closed. They mainly passively react to sensory inputs or other processes in the neural system. To the conscious (NTIC) process, the rest of the neural system and the body should be also considered as part of the environment. They retains some degree of activities during sleep and dreaming. We speculate that, during dreaming, the neural system stably forms an NTIC process with respect to its environment, i.e. the other parts of the neural system. However, at the current stage, this is mere speculation. Searching for the NTIC process(es) during dreaming is a important step to extend the scope of ICT in future research.}
    	\end{ans}
        
        
        \begin{question}
            Minor:
            \begin{enumerate}
                \item "contributions to the field" This section is just a copy paste from the abstract and thus not necessarily helpful. Not sure though what the purpose of this section is meant to be by Frontiers.
                
                \item Introduction: "We currently lack a theory... " IIT and the geometric theory of consciousness (Fekete et al.) have proposed solutions. So there are theories. The following paper should be of interest and should probably be cited:
                Fekete T, van Leeuwen C, Edelman S (2016) System, subsystem, hive: Boundary problems in computational theories of consciousness. Front Psychol 7:1041.
                
                \item $y_t$ corresponds to the content. I would argue that an activation state, without taking the system or relation between elements etc into account is meaningless and cannot capture/explain the structure of an experience. Though this issue can be dealt with at a later time.
            \end{enumerate}
        \end{question}
    
    	\begin{ans}
    		\begin{enumerate}
    			\item It's true that we were also confused about it during submission. 
    			We have modified this as follows: \\
    			\textit{"We propose a new theory of consciousness and discuss some preliminary implications."}

    			
    			\item We thank the reviewer for the reminder. We have modified our manuscript and cited the relevant references. 
    			\revise{\lineref{line:lack-theory}}
    			{
    			We currently lack a theory to identify the scale which conscious processes correspond to.
    			}
    			{
    			We currently have only few theories (e.g., Integrated Information Theory \citep{hoel2016can} and Geometric Theory of consciousness \citep{fekete2011towards,fekete2012lack}) to identify the scale which conscious processes correspond to (also see the discussion in \cite{fekete2016system}).
    			}    			
    			
    			\item We agree with the reviewer's comment. 
                In fact, we do not differentiate states of processes between activation and relation. Take neural network as an example; the relations between elements are determined by the topology of a network (structure) and its hyperparameters (e.g. activation functions). We agree that activation and relation of a neural network should be both considered. After all, they are all merely the parameters for the process of the neural network. The only difference between the two groups of the parameters is the temporal scales of changes. States of activation may have more rapid dynamics than states of relation. In ICT, the two sets of parameters do not have any qualitative differences. 
    			
    		\end{enumerate}
    		
    	\end{ans}
        
        
    \section{Reply to Reviewer 2}
        \begin{question}
			I had a few problems in reading the paper, which I think should be addressed (especially the first) before the paper is published. For detailed notes on these see below.
			
			\begin{enumerate}
				\item The coarse-graining idea seems undefined in critical ways, but the paper reads as though it is well-defined. So maybe the authors have compressed too much detail? In the formalism presented it is unclear what coarse-graining (or information closure to other grains) amounts to. With this lack of detail, it is then unclear to me why intermediate maxima in IC are a plausible result (why does IC not just decline with progressive coarse graining).
				
				\item The idea of 'simulation'. This is a more minor point but I would appreciate if the authors could be clearer on this. It is arguable whether or not consciousness simulates anything (e.g. see Hoffman's interface theory); and some of the assertions the authors make re simulation seem unfounded anyways. But it could be that they mean something different or subtle (that consciousness is linked to or represents or etc the environment)
				
				\item There were several other assertions that stood out to me as strange or wrong, but could be a matter of explanation or ignorance on my part (the feedforward system, the cut-apart system). Either way some more explanation would be good.
			\end{enumerate}
        \end{question}
    
    
    	\begin{ans}
    		We thank the reviewer for the critical comments. We have replied these comments in details in the following Q\&A. 
    	\end{ans}

        
        \begin{question}
			The English is not perfect and needs some good proofreading, though it was understandable throughout.
        \end{question}
    
    
    	\begin{ans}
    		We have invited a native English speaker for proofreading. Please inform us if it is still not clear or unreadable. 
    	\end{ans}
    
    
    	\begin{question}
			On line 182, defining C-processes as cases where 'Y is informationally closed to X'. This is now information closure in the sense of coarse-graining, but no such thing has been defined yet? Is it supposed to be so trivial that it is not required to make it explicit? To this point, closure is defined entirely in terms of system with respect to environment.
			
			Basically, I am not sure whether closure between scales is a matter of same-time (e.g. $I(Y_{t+1};X_{t+1})$) or across-time interactions ($I(Y_{t+1};X_t)$). Or could it be both?    		
    	\end{question}
    
    	\begin{ans}
    		We agree that this point is not clear. Even though the Bayesian graphs for the system-environment dependency are different from the one for the micro-macro level dependency, we apply the same definitions of information flow ($J_{t}(X \rightarrow $Y$ )$) and informational closure ($J_{t}(X \rightarrow $Y$ )=0$) to both graphs. 
    		
    % 		This is a critical assumption in ICT because applying the same definition of informational closure in both scenarios can solve the scale problem of consciousness (informational closure from one level to other levels) and construct our hypothesis about the relation between NTIC and consciousness (informational closed from a process to its environment) in an integrated framework.
    		
    % 		In terms of the Bayesian graphs for the micro-macro level dependency and the definition of informational closure between scales, we followed the conventional setting (e.g. \cite{PFANTE.2014}). It is important to note that coarse-graining does not and should not take time $Y_t=f_Y(X_t)$ (also see our Definition 1). Coarse-graining is merely a function which maps microstates of a system to macrostates, and the microstates and the macrostates are only different level of descriptions of the same system.
    		
    % 		We agree that we did not indicate this assumption explicitly and may lead to some confusion for our readers. 
    		We have added a paragraph to make this point explicit. 
    		
    		\addnew{\lineref{line:IC2CG}}{
    			Note that, here we applied the same definitions of information flow (Eq.~\ref{eq:InformationFlow}) 
    			\begin{align}
    			    J_{t}(E \rightarrow Y )=I(Y_{t+1};E_t|Y_t)
    			\end{align}
    			to the system-environment dependency and the micro-macro level dependency
                 \begin{align}
    			    J_{t}(X \rightarrow Y )=I(Y_{t+1};X_t|Y_t)
    			\end{align}  
                 even though the Bayesian graphs are different in the two scenarios. Both of these settings have already been used in the literature \citep[see][]{BERTSCHINGER.2006, PFANTE.2014}).
    		}	
    	\end{ans}
    
    
    	\begin{question}            
    		On line 241: '.. not sufficiently coarse-grained variables have low values of NTIC', this is phrased as though it is necessarily true (and also that 'we saw above', though I do not see above where this is justified), but is it?
    		
    		At the very finest grain, wouldn't even all the most 'stochastic' dynamics of a system be accounted for by prior states of the system, or by the environment? Why wouldn't we assume that NTIC *only decreases* as the system is coarse-grained (as number of elements/states is decreased), for similar reasons as it must be zero at a 1-element 1-state system as the authors note? This seems an important point to be very clear on\dots
    	\end{question}
    
    	\begin{ans}
        	We understand that this section in the last version is very unclear. Therefore, to make this point clear, we have added a new paragraph and made a significant revision of this section. In short, we more formally describe how NTIC may change non-monotonically from the finest microscale to the coarsest macroscale. Please see our revised manuscript from Line \lineref{line:non-monotonic} to Line \lineref{line:non-monotonic_end}.
    	\end{ans}
    
    
    	\begin{question}
    		on line 263: 'NTIC processes encodes environmental information in its state. This suggests that a NTIC process can be considered as a process that simulates the environmental dynamics.'
    		
    		Why does encoding suggest simulation? An encoding *could* be a simulation, but it could well be nothing like a simulation, if we understand simulation to mean something like an imitation or reconstruction of some structure or dynamics. Two totally different environmental situations could potentially be encoded in exactly the same way (eg. as a string of 1s and 0s).
    		
    		The 'simulation' notion is brought up again in section 5.2 (line 344), citing Bertschinger et al, though I do not find the idea in that paper.. I think authors need to be clearer on what they mean by 'simulation' to make this point.
    	\end{question}
    
    	\begin{ans}
    		The notion of simulation is the same as the 'Modeling' case on Page 4 in \cite{BERTSCHINGER.2006}: 
    		\begin{quote}
		    	\textit{"B2)~Modeling: The system reaches synchronization and internalizes the correlations observed in the environment by building up own structures."}
    		\end{quote}
    	    
    	    To avoid any confusion to our reader, in this revision, we added a new subsection \ref{sec:causality} to describe the scenario of modelling.
    		Also, we replaced "simulation" and "encoding" with "modelling" in many places in this revision. We hope that this change can make our point more clear. 
    	\end{ans}
    
   	\begin{question}
			line 306: 'Blindsight patients\dots make above chancel-level visual judgments without having any conscious perception about visual stimuli' I am not sure this characterization of blindsight is correct, it may be a matter of the phrasing. It could be - or probably is - the case that 'blindsight' patients always have some conscious experience of what drives their correct responses, but that the 'visual character' of these experiences is degraded or missing.
			(Overgaard, Experimental Brain Research 2011)
			for a specific example
			(Mazzi, Bagattini, Savazzi; Frontiers in Psychology, 2016)
    	\end{question}
    
    
   		\begin{ans}
   			Yes, we specifically wanted to address the visual character of their experience. We agree that some patients still preserve some forms of conscious experience. 
   			We have changed our sentence and cited the relevant references as follows:
   			\revise{\lineref{line:r2q6}}
   			{
   				Blindsight patients are able to track objects, avoid obstacles, and make above chance-level visual judgements without having any conscious perception about visual stimuli.
   			}
   			{
   				Blindsight patients are able to track objects, avoid obstacles, and make above chance-level visual judgements with degraded or missing visual experience. (However, in some cases, they may still preserve some forms of conscious experience, see \cite{overgaard2011visual, mazzi2016blind}.) 
   			}
   		\end{ans}

    
    	\begin{question}
            on Line 316: On the issue of a feedforward network, the current state of a feedforward network with more than one layer is certainly driven by its own past states! So, mutual information of a feedforward network over a time lag should not be zero, unless I am misunderstanding something here?
			At the same time, I can see a version of the authors' argument here - for a unit in a feedforward network with depth (distance-from-input) of N, a time lag of N time steps would always account fully for the states of the element. Is this the idea?		
    	\end{question}
    
 		\begin{ans}
 		    The reviewer is correct. As we have now made clear in the case of a deterministic observation process a feedforward network (or a copying process) can be informationally closed and also maintain mutual information such that it is conscious according to ICT. We call such process passive adaptation processes and introduce this in the new section \ref{sec:causality}. We mention the possibility of conscious feedforward networks now in section \ref{sec:reflexive} and add a footnote specific for n-layer feedforward networks at Line \lineref{line:feedforward}. Note that most observation processes in the real world are not deterministic so that most passive adaptation processes aren't conscious.
 		\end{ans}
 	
    
    	\begin{question}
    		on line 441: under the 'Prediction after system damaged', it is suggested that ICT predicts cutting a system in half would render both halves unconscious. But this would only be the case if neither half contains its own C-processes, yes? Since ICT allows that many C-processes can exist at the same time, it would have to be some special case for this prediction to hold true. So it seems to me the prediction is actually similar to that of IIT.
    	\end{question}
    
    
    	\begin{ans}
        	We assume that we have one conscious (NTIC) process involving information in both brain hemispheres. Namely, the process is informationally closed only when we consider the information in both hemispheres. We agree that if both hemispheres have their own NTIC process ICT should predict no change of conscious experience before and after cutting. Cutting should not make any difference because they are informationally closed with respect to each other. We also agree that this prediction is relatively premature. Systematical comparisons between model predictions can be done by rigorous modelling studies in the future. We also weakened our statement by added the following sentence:
        	
        	\addnew{\lineref{line:r2-cutting}}{Nevertheless, this prediction is relatively premature. Systematical comparisons between model predictions can be done by rigorous modelling studies in the future. }
        	
    	\end{ans}
    
                
        \begin{question}                              
            Line 540: the theory doesn't really seem to intend to solve the hard problem(s) at all, much less 'completely solve'.            
            I was expecting the problem of dreaming to come up in the last section (maybe along with SMC for which it is a serious problem). When dreaming the information between environment and the system is virtually zero; is this a problem for ICT? Also, more specific phenomena like the eigengrau - if you take away all visual input, for long enough, I do not lose my visual experiences - rather they take on a special state. Does ITC need to accept the possibility that even *trivial* IC can be a conscious process?
        \end{question}
    
    	\begin{ans}
    		We appreciate the reviewer to bring up the hard problem of consciousness and dreaming. This is a very good question and dreaming really poses a challenge for ICT. At the moment we can only speculate about possible solutions. One point We want to emphasise is that not all the processes in the neural system are NTIC processes. To the conscious (NTIC) process, the rest of the neural system should be considered as part of the environment. This notion is shortly indicated at line \lineref{line:neu-env} in the original manuscript. We speculate that, during dreaming, the neural system can stably form the NTIC process with respect to its environment, i.e. other parts of the neural system. The same idea can be also applied to phenomena like Eigengrau. However, at the current stage, this is mere speculation so we restrained ourself from making the statement in our last version of the manuscript. However, we thank the reviewer for bringing up this important question. We believe that this is still worth mentioning. We have added a short paragraph as follows:
    		
            \addnew{\lineref{line:dream}}{Explaining conscious experience during dreaming is always a challenge to theories of consciousness. ICT currently does not have a certain answer to dreaming. However, we want to emphasise that not all the processes in the neural system are NTIC since some processes are not informationally closed. They mainly passively react to sensory inputs or other processes in the neural system. To the conscious (NTIC) process, the rest of the neural system and the body should be also considered as part of the environment. They retains some degree of activities during sleep and dreaming. We speculate that, during dreaming, the neural system stably forms an NTIC process with respect to its environment, i.e. the other parts of the neural system. However, at the current stage, this is mere speculation. Searching for the NTIC process(es) during dreaming is a important step to extend the scope of ICT in future research.}
    		    
    		Finally, we believe that this is a good
    		empirical question that can and should be tested in future studies. 
    	\end{ans}

	\bibliography{ref}
\end{document}
